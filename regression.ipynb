{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Coefficients (Beta): [-5.92798538e+01  8.12870957e-04 -4.13705840e+00  4.15185161e+00\n",
      " -2.58259761e+00  2.28732093e+02]\n",
      "Root Mean Squared Error (RMSE): 50.9378\n",
      "R-squared (R2): -0.0927\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. Load Dataset\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the dataset from a CSV file.\n",
    "    Args:\n",
    "        file_path (str): Path to the dataset.\n",
    "    Returns:\n",
    "        DataFrame: Loaded dataset.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# 2. Preprocessing Functions\n",
    "def preprocess_data(df, categorical_columns, numerical_columns, target_column):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by encoding categorical columns and scaling numerical columns.\n",
    "    Args:\n",
    "        df (DataFrame): Input dataset.\n",
    "        categorical_columns (list): List of categorical columns.\n",
    "        numerical_columns (list): List of numerical columns to scale.\n",
    "        target_column (str): Target column for prediction.\n",
    "    Returns:\n",
    "        np.ndarray: Feature matrix X.\n",
    "        np.ndarray: Target vector y.\n",
    "    \"\"\"\n",
    "    # Encode categorical columns\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "    # Scale numerical columns\n",
    "    for col in numerical_columns:\n",
    "        df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "\n",
    "    # Split features and target\n",
    "    X = df.drop(target_column, axis=1).values\n",
    "    y = df[target_column].values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# 3. Add Intercept to Feature Matrix\n",
    "def add_intercept(X):\n",
    "    \"\"\"\n",
    "    Add a column of ones to the feature matrix for the intercept.\n",
    "    Args:\n",
    "        X (np.ndarray): Original feature matrix.\n",
    "    Returns:\n",
    "        np.ndarray: Feature matrix with intercept column.\n",
    "    \"\"\"\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    return np.hstack((intercept, X))\n",
    "\n",
    "# 4. Train Model Using Normal Equation\n",
    "def train_linear_regression(X, y):\n",
    "    \"\"\"\n",
    "    Train a linear regression model using the normal equation.\n",
    "    Args:\n",
    "        X (np.ndarray): Feature matrix with intercept.\n",
    "        y (np.ndarray): Target vector.\n",
    "    Returns:\n",
    "        np.ndarray: Coefficients (parameters) of the regression model.\n",
    "    \"\"\"\n",
    "    # Compute coefficients using the normal equation\n",
    "    beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return beta\n",
    "\n",
    "# 5. Predict Using the Model\n",
    "def predict(X, beta):\n",
    "    \"\"\"\n",
    "    Predict the target values using the linear regression model.\n",
    "    Args:\n",
    "        X (np.ndarray): Feature matrix with intercept.\n",
    "        beta (np.ndarray): Coefficients of the regression model.\n",
    "    Returns:\n",
    "        np.ndarray: Predicted target values.\n",
    "    \"\"\"\n",
    "    return X @ beta\n",
    "\n",
    "# 6. Evaluate the Model\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate the regression model using RMSE and R2 metrics.\n",
    "    Args:\n",
    "        y_true (np.ndarray): True target values.\n",
    "        y_pred (np.ndarray): Predicted target values.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "# 7. Main Function\n",
    "def main():\n",
    "    # File path to your dataset\n",
    "    file_path = \"./data/combined_output1.csv\"\n",
    "\n",
    "    # Load and preprocess the dataset\n",
    "    df = load_data(file_path)\n",
    "    categorical_columns = [\"state\", \"state_name\", \"disease\"]\n",
    "    numerical_columns = [\"incidence_per_capita\"]\n",
    "    target_column = \"cases\"\n",
    "\n",
    "    X, y = preprocess_data(df, categorical_columns, numerical_columns, target_column)\n",
    "\n",
    "    # Add intercept to the feature matrix\n",
    "    X = add_intercept(X)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    split_idx = int(0.8 * len(X))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "    # Train the model\n",
    "    beta = train_linear_regression(X_train, y_train)\n",
    "    print(\"Trained Coefficients (Beta):\", beta)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = predict(X_test, beta)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model(y_test, y_pred)\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights: [-7.72715242e-01  4.16719330e-06 -2.03719073e-04 -2.03719008e-04\n",
      " -9.81744159e-03  8.23740675e-01]\n",
      "\n",
      "Model Evaluation:\n",
      "MAE: 0.2224\n",
      "MSE: 0.3138\n",
      "RMSE: 0.5601\n",
      "R2: 0.7378\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load Dataset\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the dataset from a CSV file.\n",
    "    Args:\n",
    "        file_path (str): Path to the dataset.\n",
    "    Returns:\n",
    "        DataFrame: Loaded dataset.\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "# 2. Custom Data Preprocessing\n",
    "def custom_label_encoder(df, columns):\n",
    "    \"\"\"\n",
    "    Encode categorical columns to integers manually.\n",
    "    Args:\n",
    "        df (DataFrame): Input dataset.\n",
    "        columns (list): List of categorical columns to encode.\n",
    "    Returns:\n",
    "        DataFrame: Updated dataset with encoded columns.\n",
    "        dict: Dictionary of label encoders used.\n",
    "    \"\"\"\n",
    "    label_encoders = {}\n",
    "    for col in columns:\n",
    "        unique_values = df[col].unique()\n",
    "        label_map = {value: idx for idx, value in enumerate(unique_values)}\n",
    "        df[col] = df[col].map(label_map)\n",
    "        label_encoders[col] = label_map\n",
    "    return df, label_encoders\n",
    "\n",
    "def custom_standard_scaler(df, columns):\n",
    "    \"\"\"\n",
    "    Scale numerical columns manually (zero mean, unit variance).\n",
    "    Args:\n",
    "        df (DataFrame): Input dataset.\n",
    "        columns (list): List of numerical columns to scale.\n",
    "    Returns:\n",
    "        DataFrame: Dataset with scaled numerical columns.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        df[col] = (df[col] - mean) / std\n",
    "    return df\n",
    "\n",
    "# 3. Manual Train-Test Split\n",
    "def custom_train_test_split(df, target_column, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split dataset into training and testing sets manually.\n",
    "    Args:\n",
    "        df (DataFrame): Input dataset.\n",
    "        target_column (str): Target column for prediction.\n",
    "        test_size (float): Proportion of test data.\n",
    "    Returns:\n",
    "        Tuple: Train-test split (X_train, X_test, y_train, y_test).\n",
    "    \"\"\"\n",
    "    shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    split_idx = int(len(shuffled_df) * (1 - test_size))\n",
    "    train_df = shuffled_df[:split_idx]\n",
    "    test_df = shuffled_df[split_idx:]\n",
    "    X_train = train_df.drop(target_column, axis=1).values\n",
    "    y_train = train_df[target_column].values\n",
    "    X_test = test_df.drop(target_column, axis=1).values\n",
    "    y_test = test_df[target_column].values\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# 4. Manual Linear Regression using Normal Equation\n",
    "def train_linear_regression(X_train, y_train, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Train a Linear Regression model using Normal Equation with regularization.\n",
    "    Args:\n",
    "        X_train (ndarray): Training features.\n",
    "        y_train (ndarray): Training target.\n",
    "        alpha (float): Regularization parameter.\n",
    "    Returns:\n",
    "        ndarray: Weights (coefficients) of the linear regression model.\n",
    "    \"\"\"\n",
    "    X_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
    "    identity = np.eye(X_b.shape[1])\n",
    "    identity[0, 0] = 0  # Don't regularize the bias term\n",
    "    weights = np.linalg.inv(X_b.T.dot(X_b) + alpha * identity).dot(X_b.T).dot(y_train)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def predict(X, weights):\n",
    "    \"\"\"\n",
    "    Predict using the trained Linear Regression model.\n",
    "    Args:\n",
    "        X (ndarray): Features.\n",
    "        weights (ndarray): Model weights.\n",
    "    Returns:\n",
    "        ndarray: Predicted values.\n",
    "    \"\"\"\n",
    "    # Add bias term (column of ones) to X\n",
    "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    return X_b.dot(weights)\n",
    "\n",
    "# 5. Evaluate Model\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of the model.\n",
    "    Args:\n",
    "        y_true (ndarray): True target values.\n",
    "        y_pred (ndarray): Predicted target values.\n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics (MAE, MSE, RMSE).\n",
    "    \"\"\"\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = 1 - (np.sum((y_true - y_pred) ** 2) / np.sum((y_true - np.mean(y_true)) ** 2))\n",
    "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2}\n",
    "\n",
    "# 6. Main Function\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main pipeline for disease outbreak prediction using manual Linear Regression.\n",
    "    \"\"\"\n",
    "    # File path to your dataset\n",
    "    file_path = \"./data/combined_output1.csv\"\n",
    "    \n",
    "    # Load and preprocess the dataset\n",
    "    df = load_data(file_path)\n",
    "\n",
    "    # Step 1: Manually encode categorical columns\n",
    "    categorical_columns = [\"state\", \"state_name\", \"disease\"]\n",
    "    df, label_encoders = custom_label_encoder(df, categorical_columns)\n",
    "\n",
    "    # Step 2: Manually scale numerical features\n",
    "    numerical_columns = [\"cases\", \"incidence_per_capita\"]\n",
    "    df = custom_standard_scaler(df, numerical_columns)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    target_column = \"cases\"  # Predicting number of cases\n",
    "    X_train, X_test, y_train, y_test = custom_train_test_split(df, target_column)\n",
    "\n",
    "    # Train Linear Regression model\n",
    "    weights = train_linear_regression(X_train, y_train)\n",
    "    print(f\"Trained Weights: {weights}\")\n",
    "\n",
    "    # Predict on test data\n",
    "    y_pred = predict(X_test, weights)\n",
    "\n",
    "    # Evaluate the model\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "    print(\"\\nModel Evaluation:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
